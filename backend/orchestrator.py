"""
Orchestrator: glue code to connect text, image, vision test, memory, and LLM.
Returns structured responses with optional actions.
"""
import os
import uuid
from typing import Any, Dict, Optional

from backend.tools.local_qwen_api import LocalQwenAPI
from backend.tools.image_processing import analyze_image, load_error as img_load_error, reload_model
from backend.tools.memory_manager import get_user_memory, update_user_memory
from backend.tools.reporting import generate_report
from backend.tools.symptom_extractor import extract_structured
from backend.tools.followup_questioner import generate_followups
from backend.tools.risk_assessor import assess
from backend.tools.image_quality import evaluate_image_quality


class Orchestrator:
    def __init__(self, uploads_dir: str = "uploads"):
        self.llm = LocalQwenAPI()
        self.uploads_dir = uploads_dir
        os.makedirs(self.uploads_dir, exist_ok=True)

    def _needs_vision_test(self, text: Optional[str]) -> bool:
        if not text:
            return False
        keywords = ['æ¨¡ç³Š', 'è¿‘è§†', 'è¿œè§†', 'çœ‹ä¸æ¸…', 'è§†åŠ›ä¸‹é™', 'çœ¯çœ¼']
        return any(k in text for k in keywords)

    def _should_offer_vision_test(self, text: Optional[str], struct: Dict[str, Any], risk_level: str, risk_reason: str, user_mem: Dict[str, Any]) -> bool:
        """
        ç»¼åˆåˆ¤æ–­æ˜¯å¦éœ€è¦è§¦å‘è§†åŠ›æ£€æµ‹ï¼š
        - è§¦å‘å…³é”®è¯ï¼ˆæ¨¡ç³Š/çœ‹ä¸æ¸…ç­‰ï¼‰
        - é£é™©ä¸ºä¸­/é«˜æ—¶å°šæœªæœ‰è§†åŠ›ç»“æœ
        - ç—‡çŠ¶è¿‡çŸ­æˆ–æåˆ°è§†åŠ›ä½†æœªæä¾›ç»“æœ
        """
        if user_mem.get("vision_test"):
            return False
        if self._needs_vision_test(text):
            return True
        if risk_level in ("medium", "high"):
            return True
        if text and len(text.strip()) < 10:
            return True
        if "è§†åŠ›" in (risk_reason or ""):
            return True
        return False

    def _risk_level(self, text: Optional[str]) -> str:
        if not text:
            return "low"
        high_kw = ['å‰§çƒˆç–¼ç—›', 'çªç„¶å¤±æ˜', 'è§†ç½‘è†œè„±ç¦»', 'å¤§é‡é£èšŠ', 'é—ªå…‰æ„Ÿ', 'è§†é‡ç¼ºæŸ']
        medium_kw = ['è§†åŠ›ä¸‹é™', 'æŒç»­æ¨¡ç³Š', 'å¤è§†', 'çœ¼å‹é«˜', 'é»„æ–‘ç—…å˜']
        if any(k in text for k in high_kw):
            return "high"
        if any(k in text for k in medium_kw):
            return "medium"
        return "low"
    
    def _generate_fallback_response(self, text: Optional[str], struct: Dict[str, Any], risk: str, risk_reason: str, user_mem: Dict[str, Any]) -> str:
        """å½“LLMä¸å¯ç”¨æ—¶ï¼Œç”ŸæˆåŸºç¡€å›å¤"""
        if not text:
            return "è¯·æè¿°æ‚¨çš„çœ¼éƒ¨ç—‡çŠ¶ï¼Œæˆ‘ä¼šå°½åŠ›ä¸ºæ‚¨æä¾›å»ºè®®ã€‚"
        
        # æ ¹æ®é£é™©çº§åˆ«å’Œç—‡çŠ¶ç”ŸæˆåŸºç¡€å›å¤
        response_parts = []
        
        # é£é™©æç¤º
        if risk == "high":
            response_parts.append("âš ï¸ æ ¹æ®æ‚¨çš„æè¿°ï¼Œç—‡çŠ¶è¾ƒä¸ºä¸¥é‡ï¼Œå»ºè®®å°½å¿«å°±åŒ»ã€‚")
        elif risk == "medium":
            response_parts.append("âš ï¸ å»ºè®®æ‚¨å°½å¿«å’¨è¯¢ä¸“ä¸šçœ¼ç§‘åŒ»ç”Ÿã€‚")
        
        # åŸºç¡€å»ºè®®
        if "æ¨¡ç³Š" in text or "çœ‹ä¸æ¸…" in text or "è§†åŠ›" in text:
            response_parts.append("å…³äºè§†åŠ›é—®é¢˜ï¼Œå»ºè®®ï¼š\n1. é¿å…é•¿æ—¶é—´ç”¨çœ¼\n2. ä¿æŒé€‚å½“è·ç¦»çœ‹å±å¹•\n3. å®šæœŸè¿›è¡Œè§†åŠ›æ£€æŸ¥")
            if not user_mem.get("vision_test"):
                response_parts.append("å»ºè®®è¿›è¡Œè§†åŠ›æ£€æµ‹ä»¥è·å–å‡†ç¡®æ•°æ®ã€‚")
        
        if "å¹²æ¶©" in text or "ç–²åŠ³" in text:
            response_parts.append("å…³äºçœ¼éƒ¨å¹²æ¶©/ç–²åŠ³ï¼Œå»ºè®®ï¼š\n1. å¤šçœ¨çœ¼ï¼Œä¿æŒçœ¼éƒ¨æ¹¿æ¶¦\n2. ä½¿ç”¨äººå·¥æ³ªæ¶²\n3. æ¯20åˆ†é’Ÿçœ‹è¿œå¤„20ç§’ï¼ˆ20-20-20æ³•åˆ™ï¼‰")
        
        if "ç–¼ç—›" in text or "ç—›" in text:
            response_parts.append("çœ¼éƒ¨ç–¼ç—›éœ€è¦é‡è§†ï¼Œå»ºè®®ï¼š\n1. ç«‹å³åœæ­¢ç”¨çœ¼\n2. å¦‚ç–¼ç—›æŒç»­æˆ–åŠ å‰§ï¼Œè¯·å°½å¿«å°±åŒ»\n3. é¿å…æ‰çœ¼ç›")
        
        if "é£èšŠ" in text or "é»‘å½±" in text:
            response_parts.append("å…³äºé£èšŠç—‡ï¼Œå»ºè®®ï¼š\n1. å¦‚çªç„¶å‡ºç°å¤§é‡é£èšŠæˆ–ä¼´éšé—ªå…‰ï¼Œéœ€ç«‹å³å°±åŒ»\n2. å®šæœŸæ£€æŸ¥çœ¼åº•\n3. é¿å…å‰§çƒˆè¿åŠ¨")
        
        # é€šç”¨å»ºè®®
        if not response_parts:
            response_parts.append("æ ¹æ®æ‚¨çš„æè¿°ï¼Œå»ºè®®ï¼š\n1. æ³¨æ„ä¼‘æ¯ï¼Œé¿å…è¿‡åº¦ç”¨çœ¼\n2. ä¿æŒè‰¯å¥½ç”¨çœ¼ä¹ æƒ¯\n3. å¦‚ç—‡çŠ¶æŒç»­æˆ–åŠ é‡ï¼Œè¯·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ")
        
        # æ·»åŠ æ¨¡å‹çŠ¶æ€æç¤º
        response_parts.append("\n\n[æç¤º] AIæ¨¡å‹æš‚æ—¶ä¸å¯ç”¨ï¼Œä»¥ä¸Šä¸ºåŸºç¡€å»ºè®®ã€‚å¦‚éœ€æ›´è¯¦ç»†çš„è¯Šæ–­ï¼Œè¯·ä¿®å¤æ¨¡å‹åŠ è½½é—®é¢˜ã€‚")
        
        return "\n".join(response_parts)

    def _tool_status(self) -> Dict[str, Any]:
        """Returns current availability of core tools."""
        return {
            "llm_ready": self.llm.load_error is None,
            "llm_error": self.llm.load_error,
            "oct_ready": img_load_error is None,
            "oct_error": img_load_error,
        }

    def tool_status(self) -> Dict[str, Any]:
        """Public endpoint to check tool status."""
        return self._tool_status()

    def chat(self, text: str, user_id: str, image_path: Optional[str] = None) -> Dict[str, Any]:
        # Check tools are ready
        status = self._tool_status()
        if not status["llm_ready"]:
            return {
                "error": f"LLM not ready: {status['llm_error']}",
                "need_train_model": True,
                "actions": [],
            }
        if image_path and not status["oct_ready"]:
            return {
                "error": f"OCT model not ready: {status['oct_error']}",
                "need_train_model": True,
                "actions": [],
            }

        # Load memory
        memory = get_user_memory(user_id)
        history = memory.get("chat_history", [])

        # Extract structured symptom info
        symptoms = extract_structured(text)

        # Run OCT analysis if image is provided
        oct_result = None
        if image_path:
            quality = evaluate_image_quality(image_path)
            if quality["is_good_enough"]:
                try:
                    oct_result = analyze_image(image_path)
                except Exception as e:
                    return {
                        "error": f"OCTå›¾åƒåˆ†æå¤±è´¥: {str(e)}",
                        "actions": [],
                    }
            else:
                return {
                    "answer": "æ‚¨ä¸Šä¼ çš„çœ¼éƒ¨å›¾åƒè´¨é‡ä¸ä½³ï¼Œè¯·åœ¨å…‰çº¿å……è¶³çš„æƒ…å†µä¸‹é‡æ–°æ‹æ‘„çœ¼åº•ç…§ç‰‡ã€‚",
                    "actions": [{"type": "upload_image"}],
                }

        # Run vision test if needed
        vision_result = None
        if self._needs_vision_test(text):
            # Note: actual vision test would be triggered separately via /vision-test/start
            vision_result = "å°šæœªè¿›è¡Œè§†åŠ›æ£€æµ‹ï¼Œè¯·ç‚¹å‡»è§†åŠ›æ£€æµ‹æŒ‰é’®å¼€å§‹æµ‹è¯•ã€‚"

        # Query LLM
        try:
            llm_resp = self.llm.get_health_advice(
                symptoms=symptoms["symptom_text"],
                vision_result=vision_result,
                oct_result=oct_result,
            )
            
            if llm_resp["status"] != "ok":
                return {
                    "error": f"LLM query failed: {llm_resp.get('message', 'Unknown error')}",
                    "actions": [],
                }
                
            answer = llm_resp["answer"]
        except Exception as e:
            return {
                "error": f"Failed to query LLM: {str(e)}",
                "actions": [],
            }

        # Risk assessment
        risk = self._risk_level(text)
        followups = generate_followups(symptoms)

        # Save to memory
        history.append({"role": "user", "content": text})
        history.append({"role": "assistant", "content": answer})
        update_user_memory(user_id, {"chat_history": history})

        # Generate report if needed
        report_actions = []
        if risk in ("medium", "high"):
            report_path = os.path.join(self.uploads_dir, f"{user_id}_report.pdf")
            generate_report(report_path, {
                "symptoms": symptoms,
                "vision_result": vision_result,
                "oct_result": oct_result,
                "llm_response": answer,
                "risk_level": risk,
            })
            report_actions = [{
                "type": "download",
                "text": "ä¸‹è½½è¯Šæ–­æŠ¥å‘Š",
                "url": f"/download/report/{user_id}",
            }]

        return {
            "answer": answer,
            "risk": risk,
            "followups": followups,
            "actions": [
                {"type": "upload_image"},
                {"type": "vision_test"},
                *report_actions,
            ],
        }

    def process(self, user_id: str, text: Optional[str] = None, image_file=None, vision_tester=None) -> Dict[str, Any]:
        """
        Main entry for a request. Returns structured response:
        {
            status: "ok" | "error",
            answer: str (optional),
            action: None | "vision_test",
            data: { ... }
        }
        """
        user_mem = get_user_memory(user_id)
        tool_status = self._tool_status()
        context = {
            "current_symptoms": text,
            "medical_history": user_mem.get("history", []),
            "oct_result": user_mem.get("oct_result"),
            "vision_test": user_mem.get("vision_test"),
        }

        # No input guard
        if not text and image_file is None:
            return {
                "status": "ok",
                "answer": "è¯·æè¿°æ‚¨çš„çœ¼éƒ¨ç—‡çŠ¶ï¼Œæˆ–ä¸Šä¼ çœ¼éƒ¨å›¾ç‰‡è¿›è¡Œåˆ†æã€‚",
                "message": "è¯·æè¿°æ‚¨çš„çœ¼éƒ¨ç—‡çŠ¶ï¼Œæˆ–ä¸Šä¼ çœ¼éƒ¨å›¾ç‰‡è¿›è¡Œåˆ†æã€‚",  # æ·»åŠ  message å­—æ®µ
                "action": None,
                "data": {"tool_status": tool_status}
            }

        # Handle image
        if image_file is not None:
            if tool_status["oct_error"]:
                return {
                    "status": "error",
                    "message": tool_status["oct_error"],
                    "answer": tool_status["oct_error"],  # æ·»åŠ  answer å­—æ®µ
                    "data": {"tool_status": tool_status}
                }
            image_path = self._save_uploaded_file(image_file)
            try:
                quality = evaluate_image_quality(image_path)
                if not quality.get("ok", False):
                    return {
                        "status": "error",
                        "message": "å›¾ç‰‡è´¨é‡ä¸ä½³ï¼Œå»ºè®®é‡æ–°æ‹æ‘„ã€‚",
                        "answer": "å›¾ç‰‡è´¨é‡ä¸ä½³ï¼Œå»ºè®®é‡æ–°æ‹æ‘„ã€‚",  # æ·»åŠ  answer å­—æ®µ
                        "data": {"quality": quality, "tool_status": tool_status}
                    }
                oct_result = analyze_image(image_path)
                user_mem["oct_result"] = oct_result
                update_user_memory(user_id, {"oct_result": oct_result})
                report_path = generate_report(user_id, "å›¾ç‰‡åˆ†æ", oct_result)
                return {
                    "status": "ok",
                    "answer": f"OCTåˆ†æç»“æœï¼š{oct_result}",
                    "message": f"OCTåˆ†æç»“æœï¼š{oct_result}",  # æ·»åŠ  message å­—æ®µ
                    "action": None,
                    "data": {"oct_result": oct_result, "report_path": report_path, "risk_level": self._risk_level(oct_result)}
                }
            except Exception as e:
                return {
                "status": "error", 
                "message": f"å›¾ç‰‡å¤„ç†å¤±è´¥: {e}",
                "answer": f"å›¾ç‰‡å¤„ç†å¤±è´¥: {e}"  # æ·»åŠ  answer å­—æ®µ
            }

        # Structured symptoms + risk
        struct = extract_structured(text)
        risk, risk_reason = assess(text, struct)
        followups = generate_followups(struct)

        need_vision = self._should_offer_vision_test(text, struct, risk, risk_reason, user_mem)

        # è§†åŠ›æ£€æµ‹å†³ç­–ï¼šå¦‚æœvision_testerå¯ç”¨ä¸”éœ€è¦æ£€æµ‹ï¼Œå°è¯•è¿è¡Œæ£€æµ‹
        # ä½†å³ä½¿éœ€è¦è§†åŠ›æ£€æµ‹ï¼Œä¹Ÿåº”è¯¥å…ˆè°ƒç”¨LLMç”Ÿæˆå›å¤ï¼Œç„¶ååœ¨å›å¤ä¸­å»ºè®®æ£€æµ‹
        vision_result_for_llm = None
        if need_vision and vision_tester is not None:
            try:
                vr = vision_tester.run_test()
                if vr is not None:
                    user_mem["vision_test"] = vr
                    update_user_memory(user_id, {"vision_test": vr})
                    vision_result_for_llm = vr
                    # å°†è§†åŠ›ç»“æœå¹¶å…¥ç—‡çŠ¶æè¿°ï¼Œæå‡å›ç­”å‡†ç¡®æ€§
                    text = f"{text}\nè§†åŠ›æ£€æµ‹ç»“æœï¼š{vr}"
            except Exception as e:
                # è§†åŠ›æ£€æµ‹å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨LLMç”Ÿæˆå›å¤ï¼Œä½†ä¼šåœ¨å›å¤ä¸­å»ºè®®æ£€æµ‹
                pass

        # Short input: ask for more detail
        if text and len(text.strip()) < 4:
            return {
                "status": "ok",
                "answer": "è¯·å†è¯¦ç»†æè¿°æ‚¨çš„ç—‡çŠ¶ï¼ˆå¦‚è§†åŠ›æ¨¡ç³Šã€çœ¼ç—›ã€é£èšŠç­‰ï¼‰ï¼Œä¾¿äºç»™å‡ºå»ºè®®ã€‚",
                "message": "è¯·å†è¯¦ç»†æè¿°æ‚¨çš„ç—‡çŠ¶ï¼ˆå¦‚è§†åŠ›æ¨¡ç³Šã€çœ¼ç—›ã€é£èšŠç­‰ï¼‰ï¼Œä¾¿äºç»™å‡ºå»ºè®®ã€‚",  # æ·»åŠ  message å­—æ®µ
                "action": None,
                "data": {"tool_status": tool_status, "followups": followups}
            }

        # Call LLM
        if tool_status["llm_error"]:
            # æ¨¡å‹åŠ è½½å¤±è´¥æ—¶ï¼Œæä¾›åŸºç¡€å›å¤è€Œä¸æ˜¯ç›´æ¥æŠ¥é”™
            fallback_answer = self._generate_fallback_response(text, struct, risk, risk_reason, user_mem)
            return {
                "status": "ok",  # æ”¹ä¸ºokï¼Œè®©å‰ç«¯èƒ½æ­£å¸¸æ˜¾ç¤º
                "answer": fallback_answer,
                "message": fallback_answer,  # æ·»åŠ  message å­—æ®µä½œä¸ºå¤‡ç”¨
                "data": {
                    "tool_status": tool_status,
                    "risk_level": risk,
                    "risk_reason": risk_reason,
                    "followups": followups,
                    "llm_unavailable": True,  # æ ‡è®°LLMä¸å¯ç”¨
                    "fallback": True  # æ ‡è®°è¿™æ˜¯fallbackå›å¤
                }
            }
        # æ„å»ºç—‡çŠ¶æè¿°ï¼šä¼˜å…ˆä½¿ç”¨ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æå–çš„ç»“æ„åŒ–ç—‡çŠ¶
        symptom_text = text if text else (struct.get("symptom_text", "") if struct else "")
        if not symptom_text and context.get("current_symptoms"):
            symptom_text = context["current_symptoms"]
        
        # è°ƒç”¨LLMï¼Œä¼ å…¥ç—‡çŠ¶æ–‡æœ¬è€Œä¸æ˜¯æ•´ä¸ªcontextå­—å…¸
        llm_res = self.llm.get_health_advice(
            symptoms=symptom_text,
            vision_result=user_mem.get("vision_test"),
            oct_result=user_mem.get("oct_result"),
        )
        if isinstance(llm_res, dict):
            if llm_res.get("status") == "error":
                # æœ¬åœ°æ¨¡å‹æœªå°±ç»ªæˆ–åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨fallback
                fallback_answer = self._generate_fallback_response(text, struct, risk, risk_reason, user_mem)
                return {
                    "status": "ok",
                    "answer": fallback_answer,
                    "message": fallback_answer,  # æ·»åŠ  message å­—æ®µä½œä¸ºå¤‡ç”¨
                    "data": {
                        "tool_status": tool_status,
                        "risk_level": risk,
                        "risk_reason": risk_reason,
                        "followups": followups,
                        "llm_unavailable": True,
                        "fallback": True,
                        "llm_error": llm_res.get("message")
                    }
                }
            answer = llm_res.get("answer", "")
            if not answer:
                # å¦‚æœanswerä¸ºç©ºï¼Œä½¿ç”¨fallback
                answer = self._generate_fallback_response(text, struct, risk, risk_reason, user_mem)
        else:
            answer = str(llm_res)
            if not answer or answer.strip() == "":
                # å¦‚æœanswerä¸ºç©ºï¼Œä½¿ç”¨fallback
                answer = self._generate_fallback_response(text, struct, risk, risk_reason, user_mem)

        # ç¡®ä¿answerä¸ä¸ºç©º
        if not answer or answer.strip() == "":
            answer = "æŠ±æ­‰ï¼Œæš‚æ—¶æ— æ³•ç”Ÿæˆå›å¤ã€‚è¯·ç¨åé‡è¯•ã€‚"

        risk = self._risk_level(text or answer)
        # ä¿å­˜å¯¹è¯å†å²åˆ°è®°å¿†
        history = user_mem.get("chat_history", [])
        history.append({"role": "user", "content": text})
        history.append({"role": "assistant", "content": answer})
        update_user_memory(user_id, {
            "last_response": answer,
            "chat_history": history[-20:]  # ä¿ç•™æœ€è¿‘20è½®å¯¹è¯
        })
        # å¦‚æœéœ€è¦è§†åŠ›æ£€æµ‹ä½†è¿˜æ²¡æœ‰ç»“æœï¼Œåœ¨å›å¤ä¸­æ·»åŠ å»ºè®®
        if need_vision and not user_mem.get("vision_test"):
            if answer and not answer.endswith("å»ºè®®è¿›è¡Œè§†åŠ›æ£€æµ‹"):
                answer = f"{answer}\n\nğŸ’¡ å»ºè®®ï¼šä¸ºäº†æ›´å‡†ç¡®çš„è¯Šæ–­ï¼Œå»ºè®®è¿›è¡Œè§†åŠ›æ£€æµ‹ã€‚"
        
        report_path = generate_report(user_id, text or "å’¨è¯¢", answer)
        # ç»Ÿä¸€å“åº”æ ¼å¼ï¼šç¡®ä¿ answer å’Œ message éƒ½å­˜åœ¨
        return {
            "status": "ok",
            "answer": answer,
            "message": answer,  # æ·»åŠ  message å­—æ®µä½œä¸ºå¤‡ç”¨ï¼Œç¡®ä¿å‰ç«¯èƒ½æ­£ç¡®è§£æ
            "action": "vision_test" if need_vision and not user_mem.get("vision_test") else None,
            "data": {
                "risk_level": risk,
                "followups": followups,
                "risk_reason": risk_reason,
                "report_path": report_path,
                "vision_test": user_mem.get("vision_test"),
                "oct_result": user_mem.get("oct_result"),
                "actions": ([{"type": "vision_test"}] if need_vision and not user_mem.get("vision_test") else []),
            },
        }

    def run_vision_test(self, user_id: str, tester) -> Dict[str, Any]:
        """Run vision test with provided tester instance."""
        try:
            result = tester.run_test()
            update_user_memory(user_id, {"vision_test": result})
            report_path = generate_report(user_id, "è§†åŠ›æ£€æµ‹", f"è§†åŠ›æ£€æµ‹ç»“æœï¼š{result}")
            return {
                "status": "ok",
                "answer": f"è§†åŠ›æ£€æµ‹ç»“æœï¼š{result}",
                "message": f"è§†åŠ›æ£€æµ‹ç»“æœï¼š{result}",  # æ·»åŠ  message å­—æ®µ
                "action": None,
                "data": {"vision_test": result, "report_path": report_path, "risk_level": self._risk_level(result)}
            }
        except Exception as e:
            return {
                "status": "error", 
                "message": f"è§†åŠ›æ£€æµ‹å¤±è´¥: {e}",
                "answer": f"è§†åŠ›æ£€æµ‹å¤±è´¥: {e}"  # æ·»åŠ  answer å­—æ®µ
            }

    def _save_uploaded_file(self, file):
        file_id = str(uuid.uuid4())
        filename = getattr(file, "filename", f"{file_id}.jpg")
        path = os.path.join(self.uploads_dir, filename)
        file.save(path)
        return path

